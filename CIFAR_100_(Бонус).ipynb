{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CIFAR-100 (Бонус).ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AlexR9AZ/Python_mix/blob/main/CIFAR_100_(%D0%91%D0%BE%D0%BD%D1%83%D1%81).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ENQsce6RN9BN"
      },
      "source": [
        "#CIFAR-100"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p_sge7Boze-x"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gxRTzDfNzfiI"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "InL9sTcyOA-0"
      },
      "source": [
        "Датасет [CIFAR-100](https://www.cs.toronto.edu/~kriz/cifar.html) (Canadian Institute For Advanced Research) содержит 60 000 цветных изображений размером 32 на 32 пикселя. На каждом из этих изображений есть объект одного из 100 классов. Таким образом, на каждый класс приходится по 600 картинок (500 из них - на train выборке, 100 - на test).\n",
        "\n",
        "CIFAR-100 - один из самых популярных датасетов для решения задачи классификации с помощью компьютерного зрения."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6VB9BKszOAj1"
      },
      "source": [
        "# План действий"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qTPcb6UlOGKH"
      },
      "source": [
        "\n",
        "\n",
        "1.   Импортируем все необходимые библиотеки и функции;\n",
        "2.   Загрузим датасет CIFAR-100 и подготовим его к передаче в нейронную сеть;\n",
        "3.   Возьмем архитектуру нейронной сети, которую мы использовали для решения задачи классификации на датасете MNIST;\n",
        "4.   Обучим сеть на датасете CIFAR-100;\n",
        "5.   Интерпретируем полученные результаты.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wA3e_aGARLnU"
      },
      "source": [
        "#Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z4_3uN6-SIS5"
      },
      "source": [
        "from matplotlib import pyplot as plt\n",
        "from sklearn.model_selection import train_test_split # функция \"разбиения\" выборки на train и test\n",
        "from  skimage import transform # функция, чтобы сделать картинки побольше\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3893NpPJR9rP"
      },
      "source": [
        "import keras\n",
        "from keras.datasets import cifar100\n",
        "from tensorflow.keras.applications.resnet50 import ResNet50\n",
        "from keras.models import Model\n",
        "from keras.layers import Input, Dense, AveragePooling2D, GlobalAveragePooling2D, Dropout, Flatten\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPool2D\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.callbacks import ReduceLROnPlateau \n",
        "import tensorflow as tf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1X40jvaVR1K6"
      },
      "source": [
        "# Выгрузка данных"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yghUGkeEN_UF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4586391c-cb06-4c1a-de76-fc5fa4a92f55"
      },
      "source": [
        "n_classes = 10\n",
        "(X_train, y_train), (X_test, y_test) = cifar100.load_data()\n",
        "\n",
        "n_training = X_train.shape[0]\n",
        "n_testing = X_test.shape[0]\n",
        "\n",
        "y_train = y_train.flatten()\n",
        "y_test  = y_test.flatten()\n",
        "\n",
        "print('Размерность train выборки:', X_train.shape) \n",
        "print('Размерность test выборки:', X_test.shape)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Размерность train выборки: (50000, 32, 32, 3)\n",
            "Размерность test выборки: (10000, 32, 32, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 266
        },
        "id": "TKhweIL3SJ_-",
        "outputId": "1075c5f3-bda5-498b-8032-e8912fd70b78"
      },
      "source": [
        "plt.imshow(X_train[0])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sej4EwPOXhZY"
      },
      "source": [
        "# Нормализуем данные"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ct1c41X7Xmyf"
      },
      "source": [
        "X_train = (X_train).astype('float32') / 255.0 \n",
        "X_test = (X_test).astype('float32') / 255.0 "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WJcrUPL9Xhf2"
      },
      "source": [
        "# Подготовим данные для нейронной сети"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XcFytWa0chhB"
      },
      "source": [
        "# new_shape = (224, 224, 3)\n",
        "# X_train = np.asarray([transform.resize(image, new_shape) for image in X_train])\n",
        "# X_test = np.asarray([transform.resize(image, new_shape) for image in X_test])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ri1b9ue2N1o1"
      },
      "source": [
        "# эту ячейку мы используем, так как хотим подавать в сеть картинки размером 32 на 32\n",
        "\n",
        "X_train = X_train.reshape(X_train.shape[0], 32, 32, 3)\n",
        "X_test = X_test.reshape(X_test.shape[0], 32, 32, 3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4TMJEV-HTqAV"
      },
      "source": [
        "# Создадим модель"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qgIheNLWW4kL"
      },
      "source": [
        "Обучим модель, используя архитектуру сети, которую мы написали для датасета MNIST."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jsggUjeIWyV_"
      },
      "source": [
        "BATCH_SIZE = 64\n",
        "NUM_CLASSES = 100\n",
        "EPOCHS = 10\n",
        "INPUT_SIZE = (32, 32, 3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jWamokuHW0TH"
      },
      "source": [
        "y_train = keras.utils.np_utils.to_categorical(y_train, NUM_CLASSES)\n",
        "X_train, X_validation, y_train, y_validation = train_test_split(X_train, y_train, test_size = 0.2, random_state=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FDEYivgjW0Zf"
      },
      "source": [
        "model = Sequential()\n",
        "\n",
        "#Первый conv-conv-pool блок\n",
        "model.add(Conv2D(filters = 32, kernel_size = (5,5), padding = 'Same',\n",
        "                activation = 'relu', input_shape = (32, 32, 3)))\n",
        "model.add(Conv2D(filters = 32, kernel_size = (5,5), padding = 'Same',\n",
        "                activation = 'relu'))\n",
        "model.add(MaxPool2D(pool_size = (2,2)))\n",
        "model.add(Dropout(0.25))\n",
        "          \n",
        "#Второй conv-conv-pool блок\n",
        "model.add(Conv2D(filters = 64, kernel_size = (3,3), padding = 'Same',\n",
        "                activation = 'relu'))\n",
        "model.add(Conv2D(filters = 64, kernel_size = (3,3), padding = 'Same',\n",
        "                activation = 'relu'))\n",
        "model.add(MaxPool2D(pool_size = (2,2), strides = (2,2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "#Третий conv-conv-pool блок\n",
        "model.add(Conv2D(filters = 128, kernel_size = (3,3), padding = 'Same',\n",
        "                activation = 'relu'))\n",
        "model.add(Conv2D(filters = 128, kernel_size = (3,3), padding = 'Same',\n",
        "                activation = 'relu'))\n",
        "model.add(MaxPool2D(pool_size = (2,2), strides = (2,2)))\n",
        "model.add(Dropout(0.25))\n",
        "          \n",
        "#Голова сети\n",
        "model.add(Flatten())\n",
        "model.add(Dense(256, activation = 'relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(100, activation = 'softmax'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ki5oA-jQW0ug"
      },
      "source": [
        "model.compile(loss = keras.losses.categorical_crossentropy,\n",
        "              optimizer = tf.keras.optimizers.RMSprop(),\n",
        "              metrics = ['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qfYYoVJGW01W"
      },
      "source": [
        "reduce_on_plateau = ReduceLROnPlateau(monitor='val_acc', \n",
        "                                            patience=3, \n",
        "                                            verbose=1, \n",
        "                                            factor=0.5, \n",
        "                                            min_lr=0.0001)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5qFEA0-OW07x"
      },
      "source": [
        "datagen = ImageDataGenerator()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lAMN9YFfW1CQ",
        "outputId": "d34ecbdf-4192-49d5-94ba-9ba907b3e703"
      },
      "source": [
        "datagen.fit(X_train)\n",
        "h = model.fit_generator(datagen.flow(X_train,y_train, batch_size = BATCH_SIZE),\n",
        "                        epochs = EPOCHS, \n",
        "                        validation_data = (X_validation, y_validation),\n",
        "                        verbose = 1, \n",
        "                        steps_per_epoch = X_train.shape[0] // BATCH_SIZE, \n",
        "                        callbacks=[reduce_on_plateau])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/training.py:1972: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "625/625 [==============================] - 22s 30ms/step - loss: 4.3436 - accuracy: 0.0377 - val_loss: 3.9318 - val_accuracy: 0.0876\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "Epoch 2/10\n",
            "625/625 [==============================] - 18s 29ms/step - loss: 3.8437 - accuracy: 0.1097 - val_loss: 3.6168 - val_accuracy: 0.1528\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "Epoch 3/10\n",
            "625/625 [==============================] - 18s 29ms/step - loss: 3.5394 - accuracy: 0.1614 - val_loss: 3.3792 - val_accuracy: 0.1983\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "Epoch 4/10\n",
            "625/625 [==============================] - 18s 29ms/step - loss: 3.3282 - accuracy: 0.2004 - val_loss: 3.0913 - val_accuracy: 0.2472\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "Epoch 5/10\n",
            "625/625 [==============================] - 19s 30ms/step - loss: 3.1590 - accuracy: 0.2318 - val_loss: 2.9016 - val_accuracy: 0.2759\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "Epoch 6/10\n",
            "625/625 [==============================] - 18s 29ms/step - loss: 3.0510 - accuracy: 0.2542 - val_loss: 2.8487 - val_accuracy: 0.2837\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "Epoch 7/10\n",
            "625/625 [==============================] - 18s 29ms/step - loss: 2.9559 - accuracy: 0.2704 - val_loss: 2.7662 - val_accuracy: 0.3085\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "Epoch 8/10\n",
            "625/625 [==============================] - 18s 29ms/step - loss: 2.8796 - accuracy: 0.2885 - val_loss: 2.6981 - val_accuracy: 0.3142\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "Epoch 9/10\n",
            "625/625 [==============================] - 18s 29ms/step - loss: 2.8470 - accuracy: 0.2951 - val_loss: 2.7796 - val_accuracy: 0.3066\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "Epoch 10/10\n",
            "625/625 [==============================] - 18s 29ms/step - loss: 2.8091 - accuracy: 0.3045 - val_loss: 2.6770 - val_accuracy: 0.3279\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sFs-c5giO0Ct"
      },
      "source": [
        "Обратите внимание, что на протяжении всего обучения loss падал. Это значит, что наша сеть действительно училась, просто ей не хватило времени для того, чтобы полностью обучиться и достигнуть хорошей метрики accuracy (на 10 эпохах она составляла 0.3). \n",
        "\n",
        "Таким образом, для начала можно попробовать увеличить количество эпох (EPOCHS) на обучении."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d4QHaW-3YNlp"
      },
      "source": [
        "# Возможные улучшения"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rcAnSP63YQl7"
      },
      "source": [
        "\n",
        "\n",
        "*   Усложнение архитектуры сети;\n",
        "*   Использование fine-tuning;\n",
        "*   Больше эпох на обучении.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uGGYMstobpLM"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}